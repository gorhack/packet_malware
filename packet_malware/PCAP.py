"""
Assemble PCAP files and return hash of all carved files
"""

from scapy.all import *
from scapy.utils import rdpcap
import scapy_http.http
import os
from datetime import datetime
import hashlib
import re
from Hosts import Hosts
from PcapAnalyzer import PcapAnalyzer
import Grapher


def tcpflower(pcap_file, outdir='tcpflow_capture'):
    """
    Creates directory with all tcp streams from a pcap file in the
    specified output directory.
    """
    # follow tcp stream and scan for all objects
    if os.path.exists(tcpflow_outdir):
        print("Pcap already tested..running analysis")
        pass
    cmd = 'tcpflow -a -r {} -o {}'.format(pcap_file, outdir)
    p = os.popen(cmd).readlines()


def get_filenames(path):
    files = []
    for file in os.scandir(path):
        files.append(file.name)
        # # recursively get all files in path
        # if file.is_file():
        #     files.append(r'{}/{}'.format(path, file.name))
        # elif file.is_dir():
        #     files += get_filenames(r'{}/{}'.format(path, file.name))
        # else:
        #     pass
    return files


def hash_checker(hashes):
    hashes_only = set()
    for h in hashes:
        hashes_only.add(h.md5_sum)
    # print(hashes_only)
    print("{} total files".format(len(hashes_only)))
    print("="*78)


def examine_pkts(pcap_file):
    addrs = dict()
    local_hosts = dict()
    dns_servers = set()

    print("Reading pcap...")
    pkts = rdpcap(pcap_file)
    print("Examining pcap...")
    ip_re = re.compile("^\d{1,3}(\.\d{1,3}){3}$")
    for i, pkt in enumerate(pkts):
        try:
            if (pkt.getlayer('IP') and pkt.getlayer('DHCP options') and
                    pkt.getlayer('BOOTP') and pkt[BOOTP].op == 1):
                # DHCP Lookups
                ip = pkt[IP].src
                hostname = ip

                relations = set()
                if addrs.get(ip):
                    hostname = addrs[ip][0]
                    relations = addrs[ip][1]

                try:
                    hostname = pkt[DHCP].options[2][1].decode('utf-8')
                except AttributeError as e:
                    continue

                local_hosts[ip] = hostname
                addrs[ip] = [hostname, relations]
            elif (pkt.getlayer('DNS') and pkt[DNS].an):
                # Local DNS Resolution
                """
                rdata is IP address of remote server (REGEX to verify)
                rrname is the hostname of the remote server
                ip.dst is the IP requesting to resolve the server
                """

                ip = str(pkt[DNS].an.lastlayer().rdata)
                if ip_re.match(ip):  # check if IP resolved
                    hostname = pkt[DNS].an.lastlayer().rrname.decode('utf-8')

                    relations = set()
                    if addrs.get(ip):
                        relations = addrs[ip][1]

                    relations.add(pkt.getlayer('IP').dst)

                    addrs[ip] = [hostname, relations]
            elif (pkt.getlayer('DNS') and pkt[DNS].qd and
                    pkt[DNS].qd.getlayer('DNS Question Record') and
                    pkt[DNS].rcode == 0):
                dns_servers.add(pkt.getlayer('IP').dst)
            elif pkt.getlayer('IP'):
                # Add connections
                srcip = pkt[IP].src
                dstip = pkt[IP].dst

                hostname = srcip
                relations = set()

                if addrs.get(srcip):
                    hostname = addrs[srcip][0]
                    relations = addrs[srcip][1]

                relations.add(dstip)

                addrs[srcip] = [hostname, relations]
        except TypeError as e:
            continue

    hosts = []
    for k, v in addrs.items():
        hosts.append(Hosts(k, v[0], v[1]))
    # print("\n".join("{}: {}".format(k, v) for k, v in addrs.items()))
    print('='*78)
    print("Total unique IPs: {}".format(len(hosts)))
    print("DNS Servers: {}".format(dns_servers))
    print("total unique local hosts: {}".format(len(local_hosts)))
    print("\n".join("    {}: {}".format(k, v) for k, v in local_hosts.items()))


def http_data_assembler(pcap_file, tcpflow_outdir):
    tcpflower(pcap_file, tcpflow_outdir)

    # have all file names
    files = get_filenames(tcpflow_outdir)
    # print(files)
    hashes = []
    for f in files:
        if f == 'report.xml':
            break

        # regex to match */ip.ad.dr.ess.port-ip.ad.dr.ess.port-.*
        p = re.compile(".*\d{3}(\.\d{3}){3}\.\d{5}\-\d{3}(\.\d{3}){3}\.\d{5}\-")
        if p.match(f):
            with open("{}/{}".format(tcpflow_outdir, f), 'rb') as d_file:
                data = d_file.read()
                hashes.append(PcapAnalyzer(hashlib.md5(data).hexdigest(),
                              f[:15],  # src ip address
                              f[16:21],  # src port
                              f[22:37],  # dst ip address
                              f[38:43]))  # dst port
    hash_checker(hashes)
    examine_pkts(pcap_file)


if __name__ == '__main__':
    print("="*78)
    import sys
    if len(sys.argv) < 2:
        print("Use: python PCAP.py [pcap] [outdir]\n")
        sys.exit(1)
    packet_path = sys.argv[1]
    if len(sys.argv) == 3:
        tcpflow_outdir = sys.argv[2]
    else:
        tcpflow_outdir = sys.argv[1] + '_output'
    # if os.path.exists(tcpflow_outdir):
    #     tcpflow_outdir += '_' + datetime.now().strftime("%Y.%m.%d.%H%M%S")
    http_data_assembler(packet_path, tcpflow_outdir)
    # Grapher.main()


# for i, sessions in enumerate(src):
#         # break pcap into streams and follow each stream
#         print('stream {}'.format(i))
#         print('=' * 78)
#         print(sessions)
#         # for k, v in session.iteritems():
#         #     for p in v:
#         #         print(p.time, k)
#         #     if pkt.haslayer(TCP) and pkt.getlayer(TCP).sport == 80 and pkt.haslayer(Raw):
#         #         print(pkt.getlayer(Raw).load)
#         count += 1

# dependencies: foremost, tcpflow, scapy, pyqt
# extracting tcp streams: tcpflow -r [pcap]
# file names IP addresses 000.000.000.000.00000-000.000.000.000.0000
# for file in tcpflow/ as tcpflow.out:
#   extracting files: foremost -i tcpflow.out
# for file in output/ as f:
#   hashfile = hash(f)
#   vuln = sendToScaner()
#   return (filename, hashfile, vuln)
# extracting IPs
# pkt.getlayer(IP).dst / src
# import socket
# domain = socket.gethostbyaddr([IP addr])[0]
# getting computer hostname
# pcap[119].getlayer('DHCP options').options[2] | pcap[119][IP].src

# vars to print:
    # files found
    # hash values of files
    # files that are vuln
    # IP and domain names
    # IP and domains that are vuln
